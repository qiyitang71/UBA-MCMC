# Artifact for Paper 151

In this artifact, you can find the souce code of our tool [UBA-MCMC](https://github.com/qiyitang71/UBA-MCMC) that models check Markov chain against unambiguous Buchi automata (UBA) specifications.
UBA-MCMC is distributed under the MIT license.

## Load Docker Container
Assume Docker is already installed.
```
docker run -it uba-mcmc
```

## Benchmarks
The random labelled Markov chain to reproduce the results in the paper is `./artifact/random_lmc.pm`.
The set of benchmarks (UBAs) we used for the experiments are generated on the fly and stored in [UBAs](./artifact/UBAs/) directory.

#### File input format
All automata are written in Hanoi Omega Automaton [HOA format](https://adl.github.io/hoaf/). 

An example automaton is given below:
```
HOA: v1
name: "FGa"
States: 4
Start: 0
AP: 1 "a"
acc-name: Buchi
Acceptance: 1 Inf(0)
properties: trans-labels explicit-labels state-acc complete unambiguous
properties: stutter-invariant
--BODY--
State: 0
[!0] 0
[0] 1
[0] 2
State: 1 {0}
[0] 1
[!0] 3
State: 2
[!0] 0
[0] 2
State: 3
[t] 3
--END--
```
The HOA format starts with the version (HOA: v1) and the automaton's name (name: "FGa"). 
It then specifies the number of states (States: 4) and the initial state (Start: 0). 
The atomic propositions (AP) are listed, e.g., AP: 1 "a". 
The acceptance condition is defined with acc-name: Buchi and Acceptance: 1 Inf(0), meaning state 0 must be visited infinitely often. 
Properties such as trans-labels and complete define the automaton's structure and behavior. 
The transitions are described in the --BODY--, with each stateâ€™s outgoing transitions labeled by boolean formulas that describe the conditions under which the automaton moves between states.

## Installation
Our tool as explained in the paper is of two components: automata transformation (uba2pba) and GfG model checking (prism-gfg). 
First, go to the directory for uba2pba and compile it:
```
cd uba2pba
make
```
Second, go to the directory for prism-gfg and compile it:
```
cd ../prism
make
```

## Smoke Tests
We compare with the state of the art tool for Markov chain model checking against UBA specifications, [Artifact of JCSS19](https://wwwtcs.inf.tu-dresden.de/ALGI/TR/JCSS19/).

To test whether all tools have been installed correctly, we can do the following under the **artifact** directory.
```
cd ../artifact

```

1. Test JCSS19 Artifact:
```
./test_jcss19.sh
```
The JCSS19 artifact takes as input the Markov chain *random-lmc.pm* and the UBA *uba-3.hoa* generated by our uba generator by running `uba-gen.py 3` and outputs the model checking results to *results/uba-3.txt*.
The results are also reported on terminal (time might vary):
```
Generating UBA ...
UBA Model Checking uba-3 ...
Output: #states = 7, #product = 3779, time = 0.327 s
```  

2. Test Automata Transformation (uba2pba):
```
./test_transformation.sh
```
The tool uba2pba takes as input the UBA *uba-3.hoa* by our uba generator by running `uba-gen.py 3`, and perform automata transformations to obtain a minimal GfG automata.
The result is GfG automaton in HOA format, `GFGs/gfg-3.hoa`.


3. Test GfG model checking (prism-gfg):
```
./test_gfg.sh
```
The tool extended the PRISM model checker takes as input the Markov chain *random-lmc.pm* and the GfG automaton *gfg-3.hoa* generated by our GfG generator by running `gfg-gen.py 3` and outputs the model checking results to *results/gfg-3.txt*.
The results are also reported on terminal (time might vary):
```
Generating GfG automaton ...
GFG Model Checking gfg-3 ...
Output: #states = 5, #product = 3910, total_time = 1.182 s: 0 (trans), 1.182 (mc)
```

## Full Experiments

To run all the experiments reported in this paper, use the following command:
```
./run.sh
```
This set of benchmarks should take around **2 hours** to complete.
All results are stored in the directory `./results`.


To show results, use the following command:
```
./print_data.sh
```
The results can be compared with Table 1. While execution time may vary, the overall trend should be consistent: starting from `n = 8`, our algorithm outperforms JCSS19. 
Our experiments are memory-intensive, and depending on the machine used for evaluation, results may not be available for larger `n` values. However, JCSS19 is likely to run out of memory or time before any issues occur with our algorithm.

Exit docker:
```
exit
```
to complete the evaluation.

## Model Checking Another Random Markov Chain
We randomly generate a Markov chain:
```
python3 dtmc-gen.py lmc-test.pm
```
Run our algorithm to model check it against one of our benchmarks `gfg-3.hoa`:
```
../prism/bin/prism -javamaxmem 100g -javastack 1g -timeout 30m -explicit -gfgmc -ubaverbosity 1 -gfgpower lmc-test.pm -pf 'P=?[ HOA: {"'"GFGs/gfg-3.hoa"'", "sigma_0" <- "sigma", "pi_0" <- "pi", "hash_0" <- "hash","dollar_0" <- "dollar" }]'
```
The results will shown be on terminal.


## Build Docker Container
Pull code from github:
```
```
Build docker container:
```
docker build -t uba-mcmc .
``` 
## Remove Docker Container
List all Docker containers:
```
docker ps -a
```

Find the container id you would like to remove:
```
docker rm <container_id>
```
